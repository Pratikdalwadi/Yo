Pasted-Quick-Start-Installation-pip-install-agentic-doc-Requirements-Python-version-3-9-3-10-3-11-or--1758465874107_1758465874107.txtQuick Start Installation pip install agentic-doc Requirements Python version 3.9, 3.10, 3.11 or 3.12 LandingAI agentic AI API key (get the key here) Set the API Key as an Environment Variable After you get the LandingAI agentic AI API key, set the key as an environment variable (or put it in a .env file): export VISION_AGENT_API_KEY=<your-api-key> Supported Files The library can extract data from: PDFs (any length) Images that are supported by OpenCV-Python (i.e. the cv2 library) URLs pointing to PDF or image files Basic Usage Extract Data from One Document Run the following script to extract data from one document and return the results in both markdown and structured chunks. from agentic_doc.parse import parse # Parse a local file result = parse("path/to/image.png") print(result[0].markdown) # Get the extracted data as markdown print(result[0].chunks) # Get the extracted data as structured chunks of content # Parse a document from a URL result = parse("https://example.com/document.pdf") print(result[0].markdown) #### Extract Data from Multiple Documents Run the following script to extract data from multiple documents. ```python from agentic_doc.parse import parse # Parse multiple local files file_paths = ["path/to/your/document1.pdf", "path/to/another/document2.pdf"] results = parse(file_paths) for result in results: print(result.markdown) # Parse and save results to a directory results = parse(file_paths, result_save_dir="path/to/save/results") result_paths = [] for result in results: result_paths.append(result.result_path) # result_paths: ["path/to/save/results/document1_20250313_070305.json", ...] Using field extraction from pydantic import BaseModel, Field from agentic_doc.parse import parse class ExtractedFields(BaseModel): employee_name: str = Field(description="the full name of the employee") employee_ssn: str = Field(description="the social security number of the employee") gross_pay: float = Field(description="the gross pay of the employee") employee_address: str = Field(description="the address of the employee") results = parse("mydoc.pdf", extraction_model=ExtractedFields) fields = results[0].extraction metadata = results[0].extraction_metadata print(f"Field value: {fields.employee_name}, confidence: {metadata.employee_name.confidence}") Extract Data Using Connectors The library now supports various connectors to easily access documents from different sources: Google Drive Connector Prerequisites: Follow the Google Drive API Python Quickstart tutorial first to set up your credentials. The Google Drive API quickstart will guide you through: Creating a Google Cloud project Enabling the Google Drive API Setting up OAuth 2.0 credentials After completing the quickstart tutorial, you can use the Google Drive connector as follows: from agentic_doc.parse import parse from agentic_doc.connectors import GoogleDriveConnectorConfig # Using OAuth credentials file (from quickstart tutorial) config = GoogleDriveConnectorConfig( client_secret_file="path/to/credentials.json", folder_id="your-google-drive-folder-id" # Optional ) # Parse all documents in the folder results = parse(config) # Parse with filtering results = parse(config, connector_pattern="*.pdf") Amazon S3 Connector from agentic_doc.parse import parse from agentic_doc.connectors import S3ConnectorConfig config = S3ConnectorConfig( bucket_name="your-bucket-name", aws_access_key_id="your-access-key", # Optional if using IAM roles aws_secret_access_key="your-secret-key", # Optional if using IAM roles region_name="us-east-1" ) # Parse all documents in the bucket results = parse(config) # Parse documents in a specific prefix/folder results = parse(config, connector_path="documents/") Local Directory Connector from agentic_doc.parse import parse from agentic_doc.connectors import LocalConnectorConfig config = LocalConnectorConfig() # Parse all supported documents in a directory results = parse(config, connector_path="/path/to/documents") # Parse with pattern filtering results = parse(config, connector_path="/path/to/documents", connector_pattern="*.pdf") # Parse all supported documents in a directory recursively (search subdirectories as well) config = LocalConnectorConfig(recursive=True) results = parse(config, connector_path="/path/to/documents") URL Connector from agentic_doc.parse import parse from agentic_doc.connectors import URLConnectorConfig config = URLConnectorConfig( headers={"Authorization": "Bearer your-token"}, # Optional timeout=60 # Optional ) # Parse document from URL results = parse(config, connector_path="https://example.com/document.pdf") Raw Bytes Input from agentic_doc.parse import parse # Load a PDF or image file as bytes with open("document.pdf", "rb") as f: raw_bytes = f.read() # Parse the document..